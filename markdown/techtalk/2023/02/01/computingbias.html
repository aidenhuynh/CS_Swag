<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Big Idea 5.3</h1><p class="page-description">Computing Bias</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-02-01T00:00:00-06:00" itemprop="datePublished">
        Feb 1, 2023
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/CS_Swag/categories/#markdown">markdown</a>
        &nbsp;
      
        <a class="category-tags-link" href="/CS_Swag/categories/#techtalk">techtalk</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#big-idea-53-computing-bias">Big Idea 5.3: Computing Bias</a>
<ul>
<li class="toc-entry toc-h2"><a href="#group-discussion">Group Discussion</a></li>
<li class="toc-entry toc-h2"><a href="#video-hp-computers-are-racist">Video: HP computers are racist</a></li>
<li class="toc-entry toc-h2"><a href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

    <style>
        table.submenu, th.submenu, td.submenu, tr.submenu {
            margin:auto;
            background: url(https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Rainbow-gradient-fully-saturated.svg/1200px-Rainbow-gradient-fully-saturated.svg.png);
            background-size: 300px;
            outline: 3px solid #8d8d8d;
            border: 3px solid #8d8d8d;
            text-align: left;
            padding: 8px;
            border-collapse: collapse;
        }
    </style>

<br>
<table class="submenu">
    <tr class="submenu">
        <th class="submenu"><a href="https://www.youtube.com/watch?v=V3_QjoWOKS4"><img src="http://cdn.shopify.com/s/files/1/1061/1924/products/Flushed_Face_Emoji_grande.png?v=1571606037" height="50" width="50"></a></th>
        <th class="submenu"><a href="/CS_Swag/">Home</a></th>
        <th class="submenu"><a href="/CS_Swag/about/">About Me</a></th>
        <th class="submenu"><a href="/CS_Swag/markdown/2022/09/18/timebox.html">Time Box</a></th>
        <th class="submenu"><a href="https://imgix.ranker.com/user_node_img/50057/1001139289/original/1-photo-u2?auto=format&amp;q=60&amp;fit=crop&amp;fm=pjpg&amp;dpr=2&amp;w=375">Funny picture of a bird</a></th>
        <th class="submenu"><a href="/CS_Swag/jupyter/markdown/2022/09/21/Java_Test.html#Coin-Flipper">Java Testing</a></th>
        <th class="submenu"><a href="/CS_Swag/jupyter/markdown/2022/09/21/Java_Test.html#Table-with-Java">Java Table</a></th>
        <th class="submenu"><a href="/CS_Swag/jupyter/markdown/2022/10/05/API_Test.html">API</a></th>
    </tr>
</table>
<br>
<br>
<br>


<h1 id="big-idea-53-computing-bias">
<a class="anchor" href="#big-idea-53-computing-bias" aria-hidden="true"><span class="octicon octicon-link"></span></a>Big Idea 5.3: Computing Bias</h1>

<h2 id="group-discussion">
<a class="anchor" href="#group-discussion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Group Discussion</h2>

<ul>
  <li>Age difference between users of social media platforms
    <ul>
      <li>TikTok mostly used by 10-19 year olds (32.5% of users) and least used by 50+ year olds (7.1%)</li>
      <li>Facebook mostly used by 25-34 year olds (23.7%) and least used by 13-17 year olds (3.9%)
        <ul>
          <li>I wouldn’t say that these platforms exclude certain groups, but rather are simply better fit for the respective groups.
            <ul>
              <li>TikTok is more popular because the younger generations benefit from more fast-paced video media that can be quickly and easily consumed</li>
              <li>Facebook is more popular with the older generations because the fast paced media in TikTok is too densely packed with information to be fully understood (fluid intelligence begins to drop off)</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Virtual assistants have primarily female voices because women are more prototypically seen as caring for others and in assistant roles in workplaces.
    <ul>
      <li>This is problematic because it further enforces gender roles that push women into roles that make them seem inferior to men (assisting men)</li>
      <li>This may be more beneficial for business because following this stereotype may cause more satisfaction among users because it is what they are useful</li>
    </ul>
  </li>
  <li>Algorithms that influence my decisions:
    <ul>
      <li>YouTube:
        <ul>
          <li>Recommends me videos that alter my opinions (movie/game reviews)</li>
          <li>Recommends videos that affect my mood
            <ul>
              <li>Things I dislike more likely to get interaction (comments)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Google:
        <ul>
          <li>Search algorithm gives me information that may or may not be credible</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="video-hp-computers-are-racist">
<a class="anchor" href="#video-hp-computers-are-racist" aria-hidden="true"><span class="octicon octicon-link"></span></a>Video: <a href="https://www.youtube.com/watch?v=t4DT3tQqgRM">HP computers are racist</a>
</h2>

<ul>
  <li>The owner probably doesn’t think it’s intentional but plays it off as more of a joke
    <ul>
      <li>If they seriously thought this was a problem they would have a much more serious tone than laughing about it</li>
    </ul>
  </li>
  <li>This was likely caused by a lack of testing for people of color because it perfectly follows the white person’s face.
    <ul>
      <li>Probably more white people available in the workplace for testing it</li>
      <li>Could be fixed by using a more representative pool of testers</li>
    </ul>
  </li>
  <li>This is harmful because it excludes a group of people from fully utilizing the features of the device
    <ul>
      <li>Not intended though, as HP wouldn’t exclude a group because that would be detrimental to their image and business.
        <ul>
          <li>Yes it should be fixed for the above reasons</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="conclusion">
<a class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>

<p>It is imperative that computing bias is minimized for all applications for several reasons. For one, computer bias affects the profitability of a program because making a program unusable or less optimized for a certain group reduces the possible amount of consumers and therefore reduces the possible profit. Additionally, if users find out about a difference in program performance between certain groups of people, there will be backlash from consumers that will also harm profits, even if the error was unintentional. Aside from profits, this is also important from a moral perspective because it is simply common sense to not exclude groups of people based on factors like race, as seen in the HP computer video.</p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="aidenhuynh/CS_Swag"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/CS_Swag/markdown/techtalk/2023/02/01/computingbias.html" hidden></a>
</article>
